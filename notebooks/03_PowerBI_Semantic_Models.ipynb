{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power BI Semantic Models in Microsoft Fabric\n",
    "\n",
    "This notebook demonstrates working with Power BI semantic models (formerly known as datasets) in Microsoft Fabric.\n",
    "\n",
    "## What are Semantic Models?\n",
    "\n",
    "Semantic models in Fabric provide:\n",
    "- **Business logic layer** between raw data and reports\n",
    "- **Centralized metrics** and calculations (DAX measures)\n",
    "- **Security and governance** through row-level security (RLS)\n",
    "- **Optimized query performance** with data modeling\n",
    "- **Reusability** across multiple reports and applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To run this notebook, you need:\n",
    "- A Microsoft Fabric workspace\n",
    "- Power BI Premium or Fabric capacity\n",
    "- A lakehouse or warehouse with data\n",
    "- Appropriate permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Data for Semantic Models\n",
    "\n",
    "Let's create sample data that we'll use to build a semantic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create sample dimensions and facts for a sales scenario\n",
    "print(\"Creating sample star schema data...\")\n",
    "\n",
    "# Date dimension\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=x) for x in range(365 * 2)]\n",
    "dim_date = pd.DataFrame({\n",
    "    'DateKey': [d.strftime('%Y%m%d') for d in dates],\n",
    "    'Date': dates,\n",
    "    'Year': [d.year for d in dates],\n",
    "    'Quarter': [(d.month - 1) // 3 + 1 for d in dates],\n",
    "    'Month': [d.month for d in dates],\n",
    "    'MonthName': [d.strftime('%B') for d in dates],\n",
    "    'DayOfWeek': [d.weekday() + 1 for d in dates],\n",
    "    'DayName': [d.strftime('%A') for d in dates],\n",
    "    'IsWeekend': [d.weekday() >= 5 for d in dates]\n",
    "})\n",
    "\n",
    "print(f\"✓ Created Date dimension: {len(dim_date)} rows\")\n",
    "display(dim_date.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product dimension\n",
    "products = [\n",
    "    ('P001', 'Laptop Pro 15', 'Electronics', 'Computers', 1299.99),\n",
    "    ('P002', 'Laptop Pro 13', 'Electronics', 'Computers', 999.99),\n",
    "    ('P003', 'Smartphone X', 'Electronics', 'Mobile Devices', 899.99),\n",
    "    ('P004', 'Tablet Plus', 'Electronics', 'Mobile Devices', 599.99),\n",
    "    ('P005', 'Wireless Mouse', 'Accessories', 'Input Devices', 29.99),\n",
    "    ('P006', 'Mechanical Keyboard', 'Accessories', 'Input Devices', 149.99),\n",
    "    ('P007', 'USB-C Hub', 'Accessories', 'Connectivity', 49.99),\n",
    "    ('P008', '4K Monitor', 'Electronics', 'Displays', 449.99),\n",
    "    ('P009', 'Wireless Headphones', 'Accessories', 'Audio', 199.99),\n",
    "    ('P010', 'External SSD 1TB', 'Accessories', 'Storage', 129.99)\n",
    "]\n",
    "\n",
    "dim_product = pd.DataFrame(products, columns=[\n",
    "    'ProductKey', 'ProductName', 'Category', 'SubCategory', 'ListPrice'\n",
    "])\n",
    "\n",
    "print(f\"✓ Created Product dimension: {len(dim_product)} rows\")\n",
    "display(dim_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer dimension\n",
    "np.random.seed(42)\n",
    "customer_ids = [f'C{str(i).zfill(4)}' for i in range(1, 101)]\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego']\n",
    "segments = ['Consumer', 'Corporate', 'Home Office']\n",
    "\n",
    "dim_customer = pd.DataFrame({\n",
    "    'CustomerKey': customer_ids,\n",
    "    'CustomerName': [f'Customer {i}' for i in range(1, 101)],\n",
    "    'City': np.random.choice(cities, 100),\n",
    "    'Segment': np.random.choice(segments, 100),\n",
    "    'JoinDate': [start_date + timedelta(days=np.random.randint(0, 365)) for _ in range(100)]\n",
    "})\n",
    "\n",
    "print(f\"✓ Created Customer dimension: {len(dim_customer)} rows\")\n",
    "display(dim_customer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales fact table\n",
    "np.random.seed(42)\n",
    "n_transactions = 5000\n",
    "\n",
    "fact_sales_data = []\n",
    "for i in range(n_transactions):\n",
    "    date_key = np.random.choice(dim_date['DateKey'].values)\n",
    "    product_key = np.random.choice(dim_product['ProductKey'].values)\n",
    "    customer_key = np.random.choice(dim_customer['CustomerKey'].values)\n",
    "    \n",
    "    product_price = dim_product[dim_product['ProductKey'] == product_key]['ListPrice'].values[0]\n",
    "    quantity = np.random.randint(1, 6)\n",
    "    discount_pct = np.random.choice([0, 0.05, 0.10, 0.15, 0.20], p=[0.5, 0.2, 0.15, 0.10, 0.05])\n",
    "    \n",
    "    sales_amount = product_price * quantity * (1 - discount_pct)\n",
    "    cost_amount = sales_amount * np.random.uniform(0.5, 0.7)\n",
    "    \n",
    "    fact_sales_data.append((\n",
    "        f'S{str(i+1).zfill(6)}',\n",
    "        date_key,\n",
    "        product_key,\n",
    "        customer_key,\n",
    "        quantity,\n",
    "        sales_amount,\n",
    "        cost_amount,\n",
    "        discount_pct * 100\n",
    "    ))\n",
    "\n",
    "fact_sales = pd.DataFrame(fact_sales_data, columns=[\n",
    "    'SalesKey', 'DateKey', 'ProductKey', 'CustomerKey', \n",
    "    'Quantity', 'SalesAmount', 'CostAmount', 'DiscountPercent'\n",
    "])\n",
    "\n",
    "print(f\"✓ Created Sales fact table: {len(fact_sales)} rows\")\n",
    "print(f\"\\nSales Summary:\")\n",
    "print(f\"  Total Sales: ${fact_sales['SalesAmount'].sum():,.2f}\")\n",
    "print(f\"  Total Quantity: {fact_sales['Quantity'].sum():,}\")\n",
    "print(f\"  Average Order Value: ${fact_sales['SalesAmount'].mean():,.2f}\")\n",
    "display(fact_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Saving Data to OneLake\n",
    "\n",
    "Save the star schema tables to OneLake for use in semantic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Spark DataFrames and save as Delta tables\n",
    "tables = {\n",
    "    'DimDate': dim_date,\n",
    "    'DimProduct': dim_product,\n",
    "    'DimCustomer': dim_customer,\n",
    "    'FactSales': fact_sales\n",
    "}\n",
    "\n",
    "for table_name, df_pandas in tables.items():\n",
    "    # Convert to Spark DataFrame\n",
    "    df_spark = spark.createDataFrame(df_pandas)\n",
    "    \n",
    "    # Save as Delta table\n",
    "    # df_spark.write.format(\"delta\") \\\n",
    "    #     .mode(\"overwrite\") \\\n",
    "    #     .save(f\"Tables/{table_name}\")\n",
    "    \n",
    "    print(f\"✓ {table_name} ready to save ({len(df_pandas)} rows)\")\n",
    "\n",
    "print(\"\\n✓ All tables prepared for semantic model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Model Design Principles\n",
    "\n",
    "### Star Schema Design:\n",
    "- **Fact tables**: Contain measures (numerical values)\n",
    "- **Dimension tables**: Contain attributes for filtering and grouping\n",
    "- **Relationships**: Connect facts to dimensions via keys\n",
    "\n",
    "### Best Practices:\n",
    "1. Use **surrogate keys** for relationships\n",
    "2. Keep dimension tables **denormalized**\n",
    "3. Create **date/calendar** dimension\n",
    "4. Define clear **relationships** (one-to-many)\n",
    "5. Use **meaningful names** for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Semantic Model\n",
    "\n",
    "### Via Power BI Desktop:\n",
    "1. Open Power BI Desktop\n",
    "2. Get Data → Lakehouse or Warehouse\n",
    "3. Select your tables\n",
    "4. Model the data:\n",
    "   - Define relationships\n",
    "   - Create hierarchies\n",
    "   - Add DAX measures\n",
    "   - Configure table properties\n",
    "5. Publish to Fabric workspace\n",
    "\n",
    "### Via Fabric Portal:\n",
    "1. Navigate to workspace\n",
    "2. Create \"Semantic Model\" from Lakehouse\n",
    "3. Select tables to include\n",
    "4. Configure relationships\n",
    "5. Add measures using DAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Common DAX Measures\n",
    "\n",
    "DAX (Data Analysis Expressions) is used to create calculated measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common DAX patterns (to be created in Power BI)\n",
    "dax_measures = \"\"\"\n",
    "-- Basic Aggregations\n",
    "Total Sales = SUM(FactSales[SalesAmount])\n",
    "Total Quantity = SUM(FactSales[Quantity])\n",
    "Total Cost = SUM(FactSales[CostAmount])\n",
    "\n",
    "-- Calculated Measures\n",
    "Profit = [Total Sales] - [Total Cost]\n",
    "Profit Margin = DIVIDE([Profit], [Total Sales], 0)\n",
    "Average Order Value = DIVIDE([Total Sales], DISTINCTCOUNT(FactSales[SalesKey]), 0)\n",
    "\n",
    "-- Time Intelligence\n",
    "Sales YTD = TOTALYTD([Total Sales], DimDate[Date])\n",
    "Sales Previous Year = CALCULATE([Total Sales], SAMEPERIODLASTYEAR(DimDate[Date]))\n",
    "Sales YoY Growth = \n",
    "    DIVIDE(\n",
    "        [Total Sales] - [Sales Previous Year],\n",
    "        [Sales Previous Year],\n",
    "        0\n",
    "    )\n",
    "\n",
    "-- Moving Averages\n",
    "Sales 3M MA = \n",
    "    CALCULATE(\n",
    "        [Total Sales],\n",
    "        DATESINPERIOD(DimDate[Date], LASTDATE(DimDate[Date]), -3, MONTH)\n",
    "    ) / 3\n",
    "\n",
    "-- Ranking\n",
    "Product Rank = \n",
    "    RANKX(\n",
    "        ALL(DimProduct[ProductName]),\n",
    "        [Total Sales],\n",
    "        ,\n",
    "        DESC,\n",
    "        DENSE\n",
    "    )\n",
    "\n",
    "-- Conditional Logic\n",
    "High Value Sales = \n",
    "    CALCULATE(\n",
    "        [Total Sales],\n",
    "        FactSales[SalesAmount] > 500\n",
    "    )\n",
    "\n",
    "-- Distinct Counts\n",
    "Customer Count = DISTINCTCOUNT(FactSales[CustomerKey])\n",
    "Product Count = DISTINCTCOUNT(FactSales[ProductKey])\n",
    "\n",
    "-- Percentage Calculations\n",
    "% of Total Sales = \n",
    "    DIVIDE(\n",
    "        [Total Sales],\n",
    "        CALCULATE([Total Sales], ALL(DimProduct)),\n",
    "        0\n",
    "    )\n",
    "\n",
    "-- Running Totals\n",
    "Running Total Sales = \n",
    "    CALCULATE(\n",
    "        [Total Sales],\n",
    "        FILTER(\n",
    "            ALL(DimDate[Date]),\n",
    "            DimDate[Date] <= MAX(DimDate[Date])\n",
    "        )\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Common DAX Measures for Sales Semantic Model:\")\n",
    "print(dax_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing Calculations in Python\n",
    "\n",
    "Let's demonstrate equivalent calculations in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined view for analysis\n",
    "df_analysis = fact_sales.merge(dim_product, on='ProductKey') \\\n",
    "                       .merge(dim_customer, on='CustomerKey') \\\n",
    "                       .merge(dim_date, on='DateKey')\n",
    "\n",
    "# Calculate key metrics\n",
    "df_analysis['Profit'] = df_analysis['SalesAmount'] - df_analysis['CostAmount']\n",
    "df_analysis['ProfitMargin'] = df_analysis['Profit'] / df_analysis['SalesAmount']\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "metrics = {\n",
    "    'Total Sales': df_analysis['SalesAmount'].sum(),\n",
    "    'Total Profit': df_analysis['Profit'].sum(),\n",
    "    'Average Profit Margin': df_analysis['ProfitMargin'].mean(),\n",
    "    'Total Quantity': df_analysis['Quantity'].sum(),\n",
    "    'Unique Customers': df_analysis['CustomerKey'].nunique(),\n",
    "    'Unique Products': df_analysis['ProductKey'].nunique(),\n",
    "    'Average Order Value': df_analysis['SalesAmount'].mean()\n",
    "}\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    if 'Margin' in metric:\n",
    "        print(f\"  {metric}: {value:.2%}\")\n",
    "    elif '$' in str(value) or 'Sales' in metric or 'Profit' in metric or 'Value' in metric:\n",
    "        print(f\"  {metric}: ${value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by Category\n",
    "category_sales = df_analysis.groupby('Category').agg({\n",
    "    'SalesAmount': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Quantity': 'sum',\n",
    "    'SalesKey': 'count'\n",
    "}).round(2)\n",
    "\n",
    "category_sales.columns = ['Total Sales', 'Total Profit', 'Units Sold', 'Order Count']\n",
    "category_sales['Profit Margin %'] = (category_sales['Total Profit'] / category_sales['Total Sales'] * 100).round(2)\n",
    "category_sales = category_sales.sort_values('Total Sales', ascending=False)\n",
    "\n",
    "print(\"\\nSales by Category:\")\n",
    "display(category_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Products by Sales\n",
    "product_sales = df_analysis.groupby('ProductName').agg({\n",
    "    'SalesAmount': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "product_sales.columns = ['Total Sales', 'Total Profit', 'Units Sold']\n",
    "product_sales['Profit Margin %'] = (product_sales['Total Profit'] / product_sales['Total Sales'] * 100).round(2)\n",
    "top_products = product_sales.sort_values('Total Sales', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Products by Sales:\")\n",
    "display(top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Sales Trend\n",
    "df_analysis['YearMonth'] = df_analysis['Date'].dt.to_period('M')\n",
    "monthly_trend = df_analysis.groupby('YearMonth').agg({\n",
    "    'SalesAmount': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'SalesKey': 'count'\n",
    "}).round(2)\n",
    "\n",
    "monthly_trend.columns = ['Total Sales', 'Total Profit', 'Order Count']\n",
    "monthly_trend['Moving Avg (3M)'] = monthly_trend['Total Sales'].rolling(window=3).mean().round(2)\n",
    "\n",
    "print(\"\\nMonthly Sales Trend (Last 12 months):\")\n",
    "display(monthly_trend.tail(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Row-Level Security (RLS)\n",
    "\n",
    "RLS ensures users only see data they're authorized to access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example RLS patterns (to be implemented in Power BI)\n",
    "rls_examples = \"\"\"\n",
    "-- Role: Regional Managers (see only their region's data)\n",
    "-- In DimCustomer table:\n",
    "[City] = USERPRINCIPALNAME()\n",
    "\n",
    "-- Role: Sales Reps (see only their customers)\n",
    "-- In DimCustomer table:\n",
    "[SalesRep] = USERPRINCIPALNAME()\n",
    "\n",
    "-- Role: Category Managers (see specific categories)\n",
    "-- In DimProduct table:\n",
    "[Category] IN { \"Electronics\", \"Accessories\" }\n",
    "\n",
    "-- Dynamic Security using security table\n",
    "-- In fact table:\n",
    "[Region] IN \n",
    "    VALUES(\n",
    "        FILTER(\n",
    "            SecurityTable,\n",
    "            SecurityTable[UserEmail] = USERPRINCIPALNAME()\n",
    "        ),\n",
    "        SecurityTable[Region]\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Row-Level Security Examples:\")\n",
    "print(rls_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Querying Semantic Models\n",
    "\n",
    "### Using XMLA Endpoint:\n",
    "Semantic models can be queried programmatically using the XMLA endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Querying semantic model using DAX\n",
    "# Requires: pip install adodbapi or pyodbc\n",
    "\n",
    "dax_query_example = \"\"\"\n",
    "// DAX Query Example\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    DimProduct[Category],\n",
    "    DimDate[Year],\n",
    "    \"Total Sales\", [Total Sales],\n",
    "    \"Profit\", [Profit],\n",
    "    \"Profit Margin\", [Profit Margin]\n",
    ")\n",
    "ORDER BY DimDate[Year], [Total Sales] DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"DAX Query Example:\")\n",
    "print(dax_query_example)\n",
    "\n",
    "# Python code to execute DAX query would look like:\n",
    "python_code = \"\"\"\n",
    "import adodbapi\n",
    "\n",
    "connection_string = (\n",
    "    \"Provider=MSOLAP;\"\n",
    "    \"Data Source=powerbi://api.powerbi.com/v1.0/myorg/MyWorkspace;\"\n",
    "    \"Initial Catalog=MySemanticModel;\"\n",
    ")\n",
    "\n",
    "# Use Azure AD authentication\n",
    "conn = adodbapi.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "dax_query = '''EVALUATE TOPN(10, DimProduct, [Total Sales])'''\n",
    "cursor.execute(dax_query)\n",
    "results = cursor.fetchall()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nPython Code for Querying Semantic Model:\")\n",
    "print(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Semantic Model Refresh\n",
    "\n",
    "### Refresh Types:\n",
    "1. **Import Mode**: Data is cached, requires scheduled refresh\n",
    "2. **DirectQuery**: Queries sent to source in real-time\n",
    "3. **Composite**: Combines import and DirectQuery\n",
    "\n",
    "### Refresh Configuration:\n",
    "- Configure in Fabric portal settings\n",
    "- Set up to 48 refreshes per day (Premium)\n",
    "- Use incremental refresh for large tables\n",
    "- Monitor refresh history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Triggering refresh programmatically using Power BI REST API\n",
    "rest_api_example = \"\"\"\n",
    "# Using Power BI REST API to refresh semantic model\n",
    "\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get access token\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://analysis.windows.net/powerbi/api/.default\")\n",
    "\n",
    "# Define parameters\n",
    "workspace_id = \"YOUR_WORKSPACE_ID\"\n",
    "dataset_id = \"YOUR_DATASET_ID\"\n",
    "\n",
    "# Trigger refresh\n",
    "url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/refreshes\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token.token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Full refresh\n",
    "response = requests.post(url, headers=headers, json={\n",
    "    \"notifyOption\": \"MailOnFailure\"\n",
    "})\n",
    "\n",
    "# Check refresh status\n",
    "status_url = f\"{url}?$top=1\"\n",
    "status_response = requests.get(status_url, headers=headers)\n",
    "print(status_response.json())\n",
    "\"\"\"\n",
    "\n",
    "print(\"Semantic Model Refresh via REST API:\")\n",
    "print(rest_api_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices\n",
    "\n",
    "### Data Modeling:\n",
    "1. **Use star schema** over snowflake\n",
    "2. **Minimize table count** - consolidate where possible\n",
    "3. **Remove unused columns** to reduce model size\n",
    "4. **Use appropriate data types** (integer vs. text)\n",
    "5. **Create calculated columns** only when necessary\n",
    "\n",
    "### DAX Optimization:\n",
    "1. **Use measures** instead of calculated columns when possible\n",
    "2. **Avoid complex calculated columns** - do in source\n",
    "3. **Use CALCULATE** efficiently\n",
    "4. **Leverage variables** (VAR) for complex calculations\n",
    "5. **Test performance** with DAX Studio\n",
    "\n",
    "### Refresh Strategy:\n",
    "1. **Use incremental refresh** for large tables\n",
    "2. **Partition historical data** separately\n",
    "3. **Schedule refreshes** during off-peak hours\n",
    "4. **Monitor and alert** on failures\n",
    "\n",
    "### Security:\n",
    "1. **Implement RLS** for multi-tenant scenarios\n",
    "2. **Test RLS** thoroughly with different users\n",
    "3. **Use dynamic security** with security tables\n",
    "4. **Document security** requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "- ✅ Semantic model concepts and benefits\n",
    "- ✅ Star schema design for analytics\n",
    "- ✅ Creating dimension and fact tables\n",
    "- ✅ Common DAX measures and calculations\n",
    "- ✅ Implementing business logic\n",
    "- ✅ Row-level security patterns\n",
    "- ✅ Querying semantic models programmatically\n",
    "- ✅ Refresh strategies and automation\n",
    "- ✅ Best practices for performance and governance\n",
    "\n",
    "## Next Steps\n",
    "- Learn about data pipeline orchestration\n",
    "- Implement CI/CD for semantic models\n",
    "- Create Power BI reports using semantic models\n",
    "- Explore advanced DAX patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
