# Module 2: Data Factory - Orchestration Foundations

## Overview
Learn to orchestrate data movement and transformation using Microsoft Fabric Data Factory.

## Duration
⏱️ Estimated time: 1.5 hours

## Learning Objectives
- Create data pipelines
- Work with dataflows
- Implement data movement patterns
- Schedule and monitor pipelines
- Build pipelines that agents can trigger

## Key Topics

### 1. Creating Your First Pipeline
- Understanding pipeline components
- Activities and dependencies
- Parameters and variables

### 2. Data Movement
- Copy activity
- Source and sink connectors
- Incremental loading patterns

### 3. Orchestration for Agents
- REST API triggers
- Pipeline parameters from agents
- Return values to agents

### 4. Monitoring and Logging
- Pipeline runs
- Activity outputs
- Error handling

## Hands-On Exercises

### Exercise 1: Simple Copy Pipeline
Create a pipeline that copies data from Azure Blob to Lakehouse.

### Exercise 2: Parameterized Pipeline
Build a reusable pipeline with parameters.

### Exercise 3: Agent-Triggered Pipeline
Create a pipeline that agents can trigger programmatically.

## Assessment
- Build a pipeline that an agent can call
- Implement error handling
- Add monitoring and alerts

## Next Steps
Continue to [Module 3: Data Engineering](../03-data-engineering/README.md)

---

[← Back to Module 1](../01-setup/README.md) | [Next: Module 3 →](../03-data-engineering/README.md)
